{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "# Built-in libraries\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib as mpl\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# Makerspace libraries\n",
    "if os.path.isfile('./makerspace.py'): from makerspace import *\n",
    "#import cohort\n",
    "if os.path.isfile('./cohort.py'): from cohort import *\n",
    "#\n",
    "# else: from helpers.makerspace import *\n",
    "\n",
    "\n",
    "##############\n",
    "# timestamps #\n",
    "##############\n",
    "\n",
    "def return_unix_time(curr_time, scale=1000):\n",
    "    ''' converts a string value into a unix timestamp (millisecond) \n",
    "        this code works for the following formats:\n",
    "            - 2022-03-05 12:42:40.133000-05:00\n",
    "            - 2022-03-23T14:59:56.533Z '''\n",
    "    if 'T' in curr_time: curr_time = curr_time.replace('T', ' ')\n",
    "    if 'Z' in curr_time: curr_time = curr_time.replace('Z', '')\n",
    "    if '-05:00' in curr_time: curr_time = curr_time.replace('-05:00', '') \n",
    "    try:    \n",
    "        curr_time = datetime.strptime(curr_time, \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "        return int(curr_time.timestamp() * scale)\n",
    "    except Exception as e:\n",
    "        curr_time = datetime.strptime(curr_time, \"%Y-%m-%d %H:%M:%S\")\n",
    "        return int(curr_time.timestamp() * scale)\n",
    "\n",
    "def add_unix_time_to_df(df, scale='millisecond'): \n",
    "    ''' add a column  that represents the unix time of a dataframe '''\n",
    "    multiplier = 1\n",
    "    if scale == 'millisecond': multiplier = 1000\n",
    "    df['unix'] = df.apply(lambda x: return_unix_time(x['timestamp'],scale=multiplier), axis=1)\n",
    "\n",
    "def which_hour(curr_time):\n",
    "    ''' converts a string value into a unix timestamp (millisecond) \n",
    "        this code works for the following formats:\n",
    "            - 2022-03-05 12:42:40.133000-05:00\n",
    "            - 2022-03-23T14:59:56.533Z '''\n",
    "    if 'T' in curr_time: curr_time = curr_time.replace('T', ' ')\n",
    "    if 'Z' in curr_time: curr_time = curr_time.replace('Z', '')\n",
    "    if '-05:00' in curr_time: curr_time = curr_time.replace('-05:00', '') \n",
    "    try:    \n",
    "        curr_time = datetime.strptime(curr_time, \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "        return curr_time.hour\n",
    "    except Exception as e:\n",
    "        curr_time = datetime.strptime(curr_time, \"%Y-%m-%d %H:%M:%S\")\n",
    "        return curr_time.hour\n",
    "\n",
    "def add_hour_to_df(df):\n",
    "    df['hour'] = df.apply(lambda x: which_hour(x['timestamp']), axis=1)\n",
    "\n",
    "def convert_datetime(time_str):\n",
    "  time_zone = time_str.split('-')[-1]\n",
    "  time_zone = time_zone.split(':')[0] + time_zone.split(':')[1]\n",
    "  time_date = time_str.split(' ')[0]\n",
    "  time_time = time_str.split(' ')[1].split('-')[0]\n",
    "  reformat_time = '{} {} -{}'.format(time_date,time_time,time_zone)\n",
    "\n",
    "  try:\n",
    "    return datetime.strptime(reformat_time, '%Y-%m-%d %H:%M:%S.%f %z')\n",
    "  except:\n",
    "    return datetime.strptime(reformat_time, '%Y-%m-%d %H:%M:%S %z')\n",
    "\n",
    "def obtain_target_times(in_df_student,in_every_sec_freq):\n",
    "  \n",
    "  # obtain starting df_freq\n",
    "  df_freq = in_df_student.copy()\n",
    "  df_freq.sort_values(by=['timestamp'],inplace=True)\n",
    "  df_freq.reset_index(inplace=True,drop=True)\n",
    "\n",
    "  # obtain start_time, end_time and first target_time\n",
    "  start_time = df_freq.at[0,'timestamp']\n",
    "  end_time = df_freq.at[len(df_freq)-1,'timestamp']\n",
    "  target_time = start_time + timedelta(seconds=in_every_sec_freq)\n",
    "\n",
    "  # obtain target_times\n",
    "  target_times = [start_time]\n",
    "\n",
    "  def determine_time_diff(input_time):\n",
    "    return (input_time - target_time).total_seconds()\n",
    "\n",
    "  while target_time < end_time:\n",
    "    df_freq['time_diff'] = df_freq['timestamp'].apply(determine_time_diff)\n",
    "    df_freq = df_freq[df_freq['time_diff']>=0]\n",
    "    potential_time = df_freq.at[df_freq['time_diff'].idxmin(),'timestamp']\n",
    "    if (potential_time - target_time).total_seconds() < in_every_sec_freq:\n",
    "      target_times.append(potential_time)\n",
    "    \n",
    "    target_time = target_time + timedelta(seconds=in_every_sec_freq)\n",
    "\n",
    "  return target_times\n",
    "\n",
    "############\n",
    "# calendar #\n",
    "############\n",
    "\n",
    "def add_events(df, cohort): \n",
    "    ''' indicate when we had office hours or lab sections '''\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "    df['office'] = df['datetime'].apply(lambda x: cohort.is_office(x))\n",
    "    df['section'] = df['datetime'].apply(lambda x: cohort.is_section(x))\n",
    "\n",
    "\n",
    "########################\n",
    "# Self-touch behaviors #\n",
    "########################\n",
    "\n",
    "def add_self_touch(df, threshold=0.1):\n",
    "    ''' creates a new column called \"self_touch\" that indicates if the person\n",
    "        touched his/her face with his/her hand (1) or not (0) for each row '''\n",
    "    \n",
    "    df['self_touch'] = df.apply(lambda x: min(\n",
    "         dist_two_points_3d((x['nose_x'],x['nose_y'],x['nose_z']), \n",
    "                            (x['left_wrist_x'],x['left_wrist_y'],x['left_wrist_z'])), \n",
    "         dist_two_points_3d((x['nose_x'],x['nose_y'],x['nose_z']), \n",
    "                            (x['right_wrist_x'],x['right_wrist_y'],x['right_wrist_z']))), \n",
    "    axis=1)\n",
    "    \n",
    "    df['self_touch'] = df['self_touch'].apply(lambda x: 1 if x <= threshold else '')\n",
    "\n",
    "\n",
    "############\n",
    "# Movement #\n",
    "############\n",
    "\n",
    "def add_movement(df, threshold=5, verbose=False):\n",
    "    \n",
    "    # assumes that most people won't be moving\n",
    "    df['is_moving'] = ''\n",
    "    \n",
    "    # keep track of the last position for each person\n",
    "    positions = {}\n",
    "\n",
    "    # go through the data using numpy arrays\n",
    "    persons = df['person_identity'].to_numpy()\n",
    "    nosex = df['nose_x'].to_numpy()\n",
    "    nosey = df['nose_y'].to_numpy()\n",
    "    time = df['datetime']\n",
    "\n",
    "    # go through the data\n",
    "    #for i in range(0,df.shape[0]-1):\n",
    "    for i,v in time.items():\n",
    "\n",
    "        # get the current time\n",
    "        curr_time = time[i]\n",
    "        if type(curr_time) == str: \n",
    "            curr_time = datetime.strptime(time[i], \"%Y-%m-%d %H:%M:%S\")\n",
    "        person = persons[i]\n",
    "        if np.isnan([nosex[i],nosey[i]]).any(): continue\n",
    "        nose = transform_coordinates(nosex[i],nosey[i])\n",
    "\n",
    "        # check if this person exists\n",
    "        if person in positions.keys():\n",
    "            prev_nose = positions[person][1]\n",
    "            prev_time = positions[person][0]\n",
    "            if abs(curr_time - prev_time).total_seconds() <= 1:\n",
    "                dist = dist_two_points(nose,prev_nose)\n",
    "                df.at[i,'move_dist'] = dist\n",
    "                if dist < threshold: df.at[i,'is_moving'] = 1\n",
    "\n",
    "        # update the last seen position\n",
    "        positions[person] = (curr_time,nose)\n",
    "\n",
    "        # print progress\n",
    "        if i % 10000 == 0 and verbose:\n",
    "            sys.stdout.write(\"\\r\")\n",
    "            sys.stdout.write(str(i) + \"/\"+str(df.shape[0]))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        \n",
    "def add_joint_movement(df, joint):\n",
    "    \n",
    "    # assumes that most people won't be moving\n",
    "    df[joint+'_movement'] = ''\n",
    "    \n",
    "    # keep track of the last position for each person\n",
    "    positions = {}\n",
    "\n",
    "    # go through the data using numpy arrays\n",
    "    persons = df['person_identity'].to_numpy()\n",
    "    joint_x = df[joint+'_x'].to_numpy()\n",
    "    joint_y = df[joint+'_y'].to_numpy()\n",
    "    joint_z = df[joint+'_z'].to_numpy()\n",
    "    time = df['datetime']\n",
    "\n",
    "    # go through the data\n",
    "    for i,v in time.items():\n",
    "\n",
    "        # get the current time\n",
    "        curr_time = time[i]\n",
    "        if type(curr_time) == str: \n",
    "            curr_time = datetime.strptime(time[i], \"%Y-%m-%d %H:%M:%S\")\n",
    "        person = persons[i]\n",
    "        if np.isnan([joint_x[i],joint_y[i]]).any(): continue\n",
    "        jointxyz = joint_x[i],joint_y[i],joint_z[i]\n",
    "\n",
    "        # check if this person exists\n",
    "        if person in positions.keys():\n",
    "            prev_joint = positions[person][1]\n",
    "            prev_time = positions[person][0]\n",
    "            if abs(curr_time - prev_time).total_seconds() <= 1:\n",
    "                dist = dist_two_points_3d(jointxyz,prev_joint) * 90\n",
    "                df.at[i,joint+'_movement'] = dist\n",
    "\n",
    "        # update the last seen position\n",
    "        positions[person] = (curr_time,jointxyz)\n",
    "       \n",
    "\n",
    "\n",
    "            \n",
    "def add_two_joints_movement(df, joint1, joint2):\n",
    "    \n",
    "    # find joint name\n",
    "    joint_name = joint1.replace('right_','').replace('left_','')\n",
    "    df[joint_name+'_movement'] = ''\n",
    "    \n",
    "    # keep track of the last position for each person\n",
    "    positions = {}\n",
    "\n",
    "    # go through the data using numpy arrays\n",
    "    persons = df['person_identity'].to_numpy()\n",
    "    lx,ly,lz = df[joint1+'_x'].to_numpy(),df[joint1+'_y'].to_numpy(),df[joint1+'_z'].to_numpy()\n",
    "    rx,ry,rz = df[joint2+'_x'].to_numpy(),df[joint2+'_y'].to_numpy(),df[joint2+'_z'].to_numpy()\n",
    "    time = df['datetime']\n",
    "\n",
    "    # go through the data\n",
    "    for i,v in time.items():\n",
    "\n",
    "        # get the current time\n",
    "        curr_time = time[i]\n",
    "        if type(curr_time) == str: \n",
    "            curr_time = datetime.strptime(time[i], \"%Y-%m-%d %H:%M:%S\")\n",
    "        person = persons[i]\n",
    "        if np.isnan([lx[i],ly[i],lz[i],rx[i],ry[i],rz[i]]).any(): continue\n",
    "        l = lx[i],ly[i],lz[i]\n",
    "        r = rx[i],ry[i],rz[i]\n",
    "\n",
    "        # check if this person exists\n",
    "        if person in positions.keys():\n",
    "            prev_l,prev_r = positions[person][1],positions[person][2]\n",
    "            prev_time = positions[person][0]\n",
    "            if abs(curr_time - prev_time).total_seconds() <= 1:\n",
    "                dist = dist_two_points_3d(l,prev_l)+dist_two_points(r,prev_r)\n",
    "                df.at[i,joint_name+'_movement'] = dist * 90\n",
    "\n",
    "        # update the last seen position\n",
    "        positions[person] = (curr_time,l,r)\n",
    "    \n",
    "        \n",
    "########################\n",
    "# social Interactions  #\n",
    "########################\n",
    "\n",
    "def add_social_interactions(df, threshold=100, verbose=False):\n",
    "    ''' add two columns: 'state', which indicates someone that the person is close to;\n",
    "        and 'is_oriented_toward', which indicates someone who is close and where \n",
    "        their lines of sight (orthogonal from shoulders to nose) intersect'''\n",
    "\n",
    "    # go through the data using numpy arrays\n",
    "    persons = df['person_identity'].to_numpy()\n",
    "    lshoulderx = df['left_shoulder_x'].to_numpy()\n",
    "    lshouldery = df['left_shoulder_y'].to_numpy()\n",
    "    rshoulderx = df['right_shoulder_x'].to_numpy()\n",
    "    rshouldery = df['right_shoulder_y'].to_numpy()\n",
    "    nosex = df['nose_x'].to_numpy()\n",
    "    nosey = df['nose_y'].to_numpy()\n",
    "    time = df['datetime'].to_numpy()\n",
    "\n",
    "    # go through the data\n",
    "    for i in range(0,df.shape[0]-1):\n",
    "\n",
    "        # get the data\n",
    "        t = time[i]\n",
    "        if np.isnan([nosex[i],nosey[i]]).any(): continue\n",
    "        hx = (lshoulderx[i]+rshoulderx[i])/2.0\n",
    "        hy = (lshouldery[i]+rshouldery[i])/2.0\n",
    "        head = transform_coordinates(hx,hy)\n",
    "        nose = transform_coordinates(nosex[i],nosey[i])\n",
    "\n",
    "        # check the next entries\n",
    "        j = i+1\n",
    "        while(time[j] == time[i] and j < df.shape[0]-1):\n",
    "\n",
    "            # check if we have data\n",
    "            if not np.isnan([nosex[j],nosey[j]]).any(): \n",
    "                nosej = transform_coordinates(nosex[j],nosey[j])\n",
    "                \n",
    "                # close proximity\n",
    "                if dist_two_points(nose,nosej) < threshold: \n",
    "                    \n",
    "                    # create a column to keep track of the other person\n",
    "                    df.at[i,'state'] = persons[j]\n",
    "\n",
    "                    # check body orientation\n",
    "                    hxj = (lshoulderx[j]+rshoulderx[j])/2.0\n",
    "                    hyj = (lshouldery[j]+rshouldery[j])/2.0\n",
    "                    headj = transform_coordinates(hxj,hyj)\n",
    "                    gaze1 = compute_gaze(head,nose)\n",
    "                    gaze2 = compute_gaze(headj,nosej)\n",
    "                    if intersect(gaze1,gaze2) != None: \n",
    "                        df.at[i,'is_oriented_toward'] = persons[j]\n",
    "\n",
    "                    \n",
    "            # check the next row\n",
    "            j += 1\n",
    "\n",
    "        # print progress\n",
    "        if i % 10000 == 0 and verbose:\n",
    "            sys.stdout.write(\"\\r\")\n",
    "            sys.stdout.write(str(i) + \"/\"+str(df.shape[0]))\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "#Removes Rows with certain values (like unidentified)\n",
    "def filter_rows_by_values(df, col, values):\n",
    "    return df[~df[col].isin(values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_23416\\4158960095.py:11: DtypeWarning: Columns (14,15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_list = (pd.read_csv(file) for file in csv_files)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_23416\\4158960095.py:11: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_list = (pd.read_csv(file) for file in csv_files)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_23416\\4158960095.py:11: DtypeWarning: Columns (14,15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_list = (pd.read_csv(file) for file in csv_files)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_23416\\4158960095.py:11: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_list = (pd.read_csv(file) for file in csv_files)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_23416\\4158960095.py:11: DtypeWarning: Columns (14,15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_list = (pd.read_csv(file) for file in csv_files)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_23416\\4158960095.py:11: DtypeWarning: Columns (14,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_list = (pd.read_csv(file) for file in csv_files)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_23416\\4158960095.py:11: DtypeWarning: Columns (14,15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_list = (pd.read_csv(file) for file in csv_files)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_23416\\4158960095.py:11: DtypeWarning: Columns (16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_list = (pd.read_csv(file) for file in csv_files)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_23416\\4158960095.py:11: DtypeWarning: Columns (14,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_list = (pd.read_csv(file) for file in csv_files)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_23416\\4158960095.py:11: DtypeWarning: Columns (14,15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_list = (pd.read_csv(file) for file in csv_files)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_23416\\4158960095.py:11: DtypeWarning: Columns (14,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_list = (pd.read_csv(file) for file in csv_files)\n"
     ]
    }
   ],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "#next(Data, None)  # skip the first line in the input file\n",
    "#Data Import\n",
    "#dat = pd.read_csv('2022-01-27-features.csv')\n",
    "\n",
    "# Get CSV files list from a folder\n",
    "path = 'data_folder'\n",
    "csv_files = glob.glob(path + \"/*.csv\")\n",
    "# Read each CSV file into DataFrame\n",
    "# This creates a list of dataframes\n",
    "df_list = (pd.read_csv(file) for file in csv_files)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "dat   = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        person_identity             datetime            aoi  is_moving  \\\n",
      "0                  rhea  2022-01-27 09:00:01  collaboration        NaN   \n",
      "1          unidentified  2022-01-27 09:00:01  collaboration        NaN   \n",
      "2                  yani  2022-01-27 09:00:01  collaboration        NaN   \n",
      "3               melissa  2022-01-27 09:00:01  collaboration        NaN   \n",
      "4               natalie  2022-01-27 09:00:01  collaboration        NaN   \n",
      "...                 ...                  ...            ...        ...   \n",
      "6750996          conner  2022-05-05 02:00:01  collaboration        1.0   \n",
      "6750997    unidentified  2022-05-05 02:00:01  collaboration        NaN   \n",
      "6750998            rhea  2022-05-05 02:00:01  collaboration        NaN   \n",
      "6750999            sara  2022-05-05 02:00:01          laser        NaN   \n",
      "6751000            yani  2022-05-05 02:00:01  collaboration        1.0   \n",
      "\n",
      "         move_dist  left_knee_angle  right_knee_angle  standing  \\\n",
      "0              NaN        53.483247         57.748741       NaN   \n",
      "1              NaN        38.627343         36.573315       NaN   \n",
      "2              NaN        56.374558         73.380404       NaN   \n",
      "3              NaN        66.932830         47.353248       NaN   \n",
      "4              NaN        59.273309         64.828618       NaN   \n",
      "...            ...              ...               ...       ...   \n",
      "6750996   1.000000        36.160694         23.066939       NaN   \n",
      "6750997  80.280757        63.115353         87.428165       NaN   \n",
      "6750998  26.570661       164.979753        162.169823       1.0   \n",
      "6750999   5.099020       162.104560        162.922715       1.0   \n",
      "6751000   2.000000        74.019402         81.519050       NaN   \n",
      "\n",
      "         gaze_movement  ankle_movement  wrist_movement  self_touch  office  \\\n",
      "0                  NaN             NaN             NaN         NaN     NaN   \n",
      "1                  NaN             NaN             NaN         NaN     NaN   \n",
      "2                  NaN             NaN             NaN         NaN     NaN   \n",
      "3                  NaN             NaN             NaN         NaN     NaN   \n",
      "4                  NaN             NaN             NaN         NaN     NaN   \n",
      "...                ...             ...             ...         ...     ...   \n",
      "6750996      97.340265       14.786629        3.472302         NaN     NaN   \n",
      "6750997     683.324856      198.188834      178.237294         NaN     NaN   \n",
      "6750998     813.630224       43.964633       56.081971         NaN     NaN   \n",
      "6750999      94.176938        4.061849       12.126173         NaN     NaN   \n",
      "6751000    2346.270395       53.705258       11.602133         NaN     NaN   \n",
      "\n",
      "         section  is_with is_oriented_toward observes  neck_angle        Date  \\\n",
      "0            NaN      NaN                NaN      NaN  141.363070  2022-01-27   \n",
      "1            NaN      NaN                NaN      NaN  124.912844  2022-01-27   \n",
      "2            NaN      NaN                NaN      NaN  142.375853  2022-01-27   \n",
      "3            NaN  natalie                NaN      NaN  140.824080  2022-01-27   \n",
      "4            NaN      NaN                NaN      NaN  147.544816  2022-01-27   \n",
      "...          ...      ...                ...      ...         ...         ...   \n",
      "6750996      NaN     rhea                NaN      NaN  110.376645  2022-05-05   \n",
      "6750997      NaN      NaN                NaN      NaN  162.917762  2022-05-05   \n",
      "6750998      NaN      NaN                NaN      NaN  128.277070  2022-05-05   \n",
      "6750999      NaN      NaN                NaN      NaN  107.279663  2022-05-05   \n",
      "6751000      NaN      NaN                NaN      NaN  110.887638  2022-05-05   \n",
      "\n",
      "             Time  \n",
      "0        09:00:01  \n",
      "1        09:00:01  \n",
      "2        09:00:01  \n",
      "3        09:00:01  \n",
      "4        09:00:01  \n",
      "...           ...  \n",
      "6750996  02:00:01  \n",
      "6750997  02:00:01  \n",
      "6750998  02:00:01  \n",
      "6750999  02:00:01  \n",
      "6751000  02:00:01  \n",
      "\n",
      "[6751001 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "dat[['Date', 'Time']] = dat['datetime'].str.split(' ', expand=True, regex=True)\n",
    "print(dat)\n",
    "\n",
    "\n",
    "#Weekframes:\n",
    "#dat['Date'] = dat['Date'].apply(pd.to_datetime)\n",
    "#print('done convert')\n",
    "#weeks = [g for n, g in dat.groupby(pd.Grouper(key='Date', freq='W', dropna=True))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<cohort.Cohort object at 0x000002300FCC9C10>\n"
     ]
    }
   ],
   "source": [
    "import cohort\n",
    "c = cohort.Cohort('data_folder')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_lab_sec(data, cohort):\n",
    "    data_cop = data.copy()\n",
    "    data_cop['datetime'] = pd.to_datetime(data_cop['datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "    data_cop['office'] = data_cop['datetime'].apply(lambda x: cohort.is_office(x))\n",
    "    data_cop['section'] = data_cop['datetime'].apply(lambda x: cohort.is_section(x))\n",
    "    count_removed = len(data_cop[data_cop['office'] == 1].index) + len(data_cop[data_cop['section'] == 1].index)\n",
    "    print(count_removed)\n",
    "    data_cop = data_cop[data_cop.office != 1]\n",
    "    data_cop = data_cop[data_cop.section != 1]\n",
    "    return data_cop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261901\n",
      "Done\n",
      "228085\n",
      "Done\n",
      "209762\n",
      "Done\n",
      "34086\n",
      "Done\n",
      "386560\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#dat.info()\n",
    "dat['Date'] = pd.to_datetime(dat['Date'])\n",
    "#dat.info()\n",
    "\n",
    "#SEPARATE BY WEEK\n",
    "weeks = [g for n, g in dat.groupby(pd.Grouper(key='Date', freq='W', dropna=True))]\n",
    "\n",
    "#SEPARATE BY PERIODS\n",
    "# P1 : 2022-01-27 to 2022-02-16 SMALL PROJECT\n",
    "# P2 : 2022-02-17 to 2022-03-20 BIG PROJECT\n",
    "# P3 : 2022-03-21 to 2022-04-07 BREAK\n",
    "# P4 : 2022-04-08 to 2022-04-14 SMALL PROJECT\n",
    "# P5 : 2022-04-15 to END FINAL PROJECT\n",
    "datacop1 = dat.copy()\n",
    "date_1 = datetime.strptime('2022-01-27', '%Y-%m-%d')\n",
    "date_2 = datetime.strptime('2022-02-16', '%Y-%m-%d')\n",
    "date_3 = datetime.strptime('2022-02-17', '%Y-%m-%d')\n",
    "date_4 = datetime.strptime('2022-03-20', '%Y-%m-%d')\n",
    "date_5 = datetime.strptime('2022-03-21', '%Y-%m-%d')\n",
    "date_6 = datetime.strptime('2022-04-07', '%Y-%m-%d')\n",
    "date_7 = datetime.strptime('2022-04-08', '%Y-%m-%d')\n",
    "date_8 = datetime.strptime('2022-04-14', '%Y-%m-%d')\n",
    "date_9 = datetime.strptime('2022-04-15', '%Y-%m-%d')\n",
    "\n",
    "datacop1 = datacop1[(datacop1['Date'] >= date_1) & (datacop1['Date'] <= date_2)] # small\n",
    "datacop2 = dat.copy()\n",
    "datacop2 = datacop2[(datacop2['Date'] >= date_3) & (datacop2['Date'] <= date_4)] # big\n",
    "datacop3 = dat.copy()\n",
    "datacop3 = datacop3[(datacop3['Date'] >= date_5) & (datacop3['Date'] <= date_6)] # break\n",
    "datacop4 = dat.copy()\n",
    "datacop4 = datacop4[(datacop4['Date'] >= date_7) & (datacop4['Date'] <= date_8)] # small\n",
    "datacop5 = dat.copy()\n",
    "datacop5 = datacop5[(datacop5['Date'] >= date_9)] # final\n",
    "\n",
    "periods = [datacop1, datacop2, datacop3, datacop4, datacop5]\n",
    "\n",
    "for period in periods:\n",
    "    period = remove_lab_sec(period, c)\n",
    "    print(\"Done\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#save each period to a different csv:\n",
    "n=0\n",
    "for period in periods:\n",
    "    n=n+1\n",
    "    period.to_csv(str('period'+str(str(n)+'.csv')))\n",
    "    print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
